---
layout: default
title: Demystifying True Online Threats vs. Protected Violent Speech
parent: § PROTECTING VIOLENT FREE SPEECH AND COMBATTING TRUE HOMICIDAL THREATS IN CYBERSPACE   
grand_parent: P
nav_order: 30 
---
<style>
.dont-break-out {
  /* These are technically the same, but use both */
  overflow-wrap: break-word;
  word-wrap: break-word;

     -ms-word-break: break-all;
  /* This is the dangerous one in WebKit, as it breaks things wherever */
  word-break: break-all;
  /* Instead use this non-standard one: */
  word-break: break-word;
}

.youtube-container {
    position: relative;
    width: 100%;
    height: 0;
    padding-bottom: 56.25%;
}
.youtube-video {
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
}

</style>

<div class="dont-break-out" markdown="1">

1. TOC
{:toc}

## Demystifying True Online Threats vs. Protected Violent Speech
The internet is used by violent criminals like domestic terrorists for multiple purposes including to explicitly state their intentions to harm and kill others, to engage in and share violent fantasies, to communicate with and threaten victims, and to share content like manifestos that can signify escalation.<sup>14</sup> The ability to quickly identify and respond to credible threats that are communicated in cyberspace could help police to disrupt and even prevent crimes that often result in mass injuries and casualties, but the legal definition of credible online threat speech remains unresolved.<sup>15</sup> The context of global pandemic and criminality in cyberspace make this appear to be a novel issue, but it simply represents a new direction in the decades-old debate about the types of incendiary speech that should be protected by the Constitution and the types of speech that are heinous and threatening enough to warrant prosecution. The Supreme Court has consistently held for decades that threatening speech that falls outside constitutional protections must be narrowly defined, but the Court has also steadily refused to provide clear and specific guidance regarding how credible threats should be identified.<sup>16</sup> This is an inherently difficult issue to decide from a juridical standpoint, because

***
<sup>12</sup> Rønn and Søe, “Privacy in Public,” 369-371.
{: .fs-2}
<sup>13</sup> Ibid., 367-368.
{: .fs-2}
<sup>14</sup> Recupero, “Homicide and the Internet,” 217.
{: .fs-2}
<sup>15</sup> Ibid., 224.
{: .fs-2}
<sup>16</sup> Best, “Need to Uphold Individual Rights,” 1136-1138.
{: .fs-2}
***

threatening communications involve both the original intent and behavior of the communicator and the beliefs and reactions of the message recipient.

The Supreme Court’s 1942 opinion in *Chaplinsky v. New Hampshire* established the “fighting words” doctrine, holding that speech that is intended to provoke another person to commit violent acts in the public square is not protected by the Constitution.<sup>17</sup> In its 1969 *Watts v. United States* decision the Court set a draconian standard for successfully identifying and prosecuting threatening speech, holding that a public statement that the defendant would kill the President of the United States if drafted into the Army did not constitute a true threat because the statement was conditional and lacked at least some of the necessary elements of an intentional threat.<sup>18</sup> Also in 1969, the *Brandenburg v. Ohio* majority opinion held that speech encouraging others to commit violent crimes is protected by the First Amendment of the Constitution unless that speech incites immediate criminal actions.<sup>19</sup> Interestingly, the history of legal precedent surrounding the issue of protected speech versus true threats indicates that the boundary between freedom of expression and criminal interpersonal violence is often tested by domestic extremist groups like violent protesters and the Ku Klux Klan. While the *Watts* and *Brandenburg* decisions were intended to protect citizens from being prosecuted for voicing unpopular social and political views, they also increased the difficulty of preventing murder, terror, and insurrection by shielding broad categories of violent and threatening speech under the umbrella of the First Amendment.<sup>20</sup>

In the more recent 2003 *Virginia v. Black* decision, the Supreme Court decided that the First Amendment protects cross burnings, asserting that true threats involve elements of serious intent to perpetrate criminal violence targeting a specific person or group.<sup>21</sup> While it is typically not difficult to determine whether a specific individual or group of persons has been targeted, the concept of serious intent to cause harm is very subjective and it is easy to imagine how difficult it might be for a jury to evaluate, especially in the context of digital communications. As contemporary cases illustrate, there are qualitative nuances that affect the threatening nature of online activities like posting savage and murderous fantasies about specific people on social media, creating posts that advocate violence against an individual and sharing that person’s identifiers and locational data, or describing why a particular school or residence might represent a soft target for a mass killing. The Supreme Court’s 2015 *Elonis v. United States* decision illustrates just how difficult it is to convict an individual for communicating true threats in

***
<sup>17</sup> Chaplinsky v. New Hampshire, 315 U.S. 568 (1942).
{: .fs-2}
<sup>18</sup> Watts v. United States, 394 U.S. 705 (1969).
{: .fs-2}
<sup>19</sup> Brandenburg v. Ohio, 395 U.S. 444 (1969).
{: .fs-2}
<sup>20</sup> Best, “Need to Uphold Individual Rights,” 1136-1138.
{: .fs-2}
<sup>21</sup> Virginia v. Black, 538 U.S. 343 (2003).
{: .fs-2}
***

cyberspace.<sup>22</sup> The case syllabus describes how Anthony Douglas Elonis used his Facebook page to produce explicitly violent fantasies in the form of rap lyrics targeting his wife, his co-workers, and a group of kindergarten children; but his conviction was overturned because the jury in the original case had been instructed to use a reasonableness standard rather than the stricter intent standard.<sup>23</sup>

The *Elonis* case is troubling because his wife believed his threats were credible and she pursued a restraining order, his employer believed his threats were credible and terminated his employment, the Federal Bureau of Investigation believed his threats were credible and began surveilling his online communications, and a jury decided that a reasonable person would find his threats credible; yet Elonis’s stated intention of achieving catharsis through creating rap lyrics ultimately decided the case in his favor.<sup>24</sup> *Elonis* is an illustrative example of the nexus between reasonableness, intent, and context that makes identifying and prosecuting threats in cyberspace so complex. Elonis was correct that a reasonable person standard is too broad for threat speech cases because it does not account for the mental state of the speaker, and it could result in the punishment of innocent people for unknowingly or unwilfully communicating in ways that a jury might find unacceptable.<sup>25</sup> However, it also appears that a serious intent standard is likely too narrow given that *Elonis* was able to post diagrams of his wife’s house including statements describing how easy it would be to shoot her with specific weapons from specific locations and pass these horrifying communications off as lyrical art.<sup>26</sup> Perhaps the most critical challenge posed by *Elonis* is the need for criminal justice practitioners and researchers to improve their skills in effectively analyzing context when evaluating potentially threatening social media communications. <sup>27</sup>

In light of the problems raised within Elonis, experts have recommended two potential solutions that the court system might adopt in order to make it easier to identify and prosecute true threats in cyberspace while maintaining strong safeguards protecting the innocent from punishment and shielding free speech that the majority might find inflammatory, needlessly graphic, and violent. The first recommendation involves the development of a dual reasonable-recipient and reasonable-speaker standard that integrates the intent of the speaker and the reactions of their audiences. <sup>28</sup> This proposed hybrid standard is likely the best way

***
<sup>22</sup> Elonis v. United States, 575 U.S. _ (2015).
{: .fs-2}
<sup>23</sup> Ibid.
{: .fs-2}
<sup>24</sup> Ibid.
{: .fs-2}
<sup>25</sup> Best, “Need to Uphold Individual Rights,” 1144.
{: .fs-2}
<sup>26</sup> Elonis, 575 U.S.  (2015); see Chief Justice Roberts opinion of the Court.
{: .fs-2}
<sup>27</sup> Lyrissa Barnett Lidsky and Linda Riedemann Norbut, “#I U: Considering the Context of Online Threats,” *California Law Review* 106, no. 7 (December 2018): 1885.
{: .fs-2}
<sup>28</sup> Best, “Need to Uphold Individual Rights,” 1151-1152.
{: .fs-2}
***

to provide the court system with a practicable standard for appraising credible threats that effectively reconciles the opposing goals of safeguarding free speech while protecting victims from true threats. <sup>29</sup> The second recommendation describes the creation of a context defense specific to online threat cases that would permit defendants to introduce contextual evidence demonstrating nonthreatening intent and incorporating special jury instructions describing distinctions between true credible threats and constitutionally protected speech that is violent or distasteful.<sup>30</sup> Incorporating these types of recommendations could represent a critical step toward protecting free speech while better equipping police and prosecutors to protect citizens from threats like stranger-initiated homicide, mass killings, and terrorism.

***

#### Table of Contents
{: .no_toc}

<ul><li> <a href="/docs/P/PROTECTING-VIOLENT-FREE-SPEECH-AND-COMBATTING-TRUE-HOMICIDAL-THREATS-IN-CYBERSPACE-1/">Introduction</a></li><li> <a href="/docs/P/PROTECTING-VIOLENT-FREE-SPEECH-AND-COMBATTING-TRUE-HOMICIDAL-THREATS-IN-CYBERSPACE-2/">Misconstrual of Privacy in Cyberspace</a></li><li> <a href="/docs/P/PROTECTING-VIOLENT-FREE-SPEECH-AND-COMBATTING-TRUE-HOMICIDAL-THREATS-IN-CYBERSPACE-3/">Demystifying True Online Threats vs. Protected Violent Speech</a></li><li> <a href="/docs/P/PROTECTING-VIOLENT-FREE-SPEECH-AND-COMBATTING-TRUE-HOMICIDAL-THREATS-IN-CYBERSPACE-4/">Cyberspace is a Hunting Ground</a></li><li> <a href="/docs/P/PROTECTING-VIOLENT-FREE-SPEECH-AND-COMBATTING-TRUE-HOMICIDAL-THREATS-IN-CYBERSPACE-5/">Shrinking Big Data</a></li><li> <a href="/docs/P/PROTECTING-VIOLENT-FREE-SPEECH-AND-COMBATTING-TRUE-HOMICIDAL-THREATS-IN-CYBERSPACE-6/">Behavioral Profiling and Human Judgment</a></li><li> <a href="/docs/P/PROTECTING-VIOLENT-FREE-SPEECH-AND-COMBATTING-TRUE-HOMICIDAL-THREATS-IN-CYBERSPACE-7/">Conclusion</a></li><li> <a href="/docs/P/PROTECTING-VIOLENT-FREE-SPEECH-AND-COMBATTING-TRUE-HOMICIDAL-THREATS-IN-CYBERSPACE-8/">Bibliography</a></li></ul>

***

</div>
